
\section{Image Reconstruction}

\begin{frame}{Aim: image reconstruction using *pre-trained* generator models}

\begin{columns}
 \begin{column}{0.5\textwidth}
  
  \begin{itemize}
   \item Adapt the state-of-the-art StyleGAN2 for medical image generation and reconstruction

   \vspace{2em}
   
   \item Vision: bring this technology to medicine
  \end{itemize}
  
 \vspace{1em}
  
 \incw{mriall}{1} 
  
  
 \end{column} 
 
 \begin{column}{0.5\textwidth}
 \centering
 StyleGAN2 (Karras et al, 2019)
 \inc{stylegan} 
 \end{column}

\end{columns}



\end{frame}

\begin{frame}{Many image reconstruction methods exist, but have several limitations}


\begin{columns}
 \begin{column}{0.5\textwidth}

 \begin{itemize}
 \item Require large amounts of training data
 
 \vt
 
 \item Learned inverse corruption functions are task-specific
 
 \vt 
 
 \item Cannot deal with distribution shifts:
 \begin{itemize}
   \item in inputs: e.g. older populations
   \item in corruption type: e.g. change in blur kernel
 \end{itemize}
 
  
 \end{itemize}

 \end{column}

 \begin{column}{0.5\textwidth}
  \centering
\incw{task-specific}{0.8}
  
 \end{column}
\end{columns} 
 

  


 
 
\end{frame}



\begin{frame}{Limitation 1: Large computational requirements}

\begin{itemize}
 \item State-of-the-art deep learning methods are becoming difficult to train:
 \begin{itemize}
 \item Large computational resources
 \item Large datasets
 \item Long time to converge
 
 \incw{datacenter}{0.7}
\end{itemize}
\vo
 \item Currently few labs/companies have the resources to train them

\vo
 \item Solutions moving forward:
 \begin{itemize}
\item Adapting previously-trained models
\item Combine smaller models into larger ones
\end{itemize}
\end{itemize}

 
\end{frame}

\begin{frame}{Limitation 2: Distribution shifts require re-training}


\begin{itemize}
 \item Distribution shifts happen all the time:
 \begin{itemize}
 \item Changes in hospital scanners, protocols, software upgrades
 \item Can be continuous: population getting older due to better healthcare
\end{itemize}

\vspace{2em}
 \item Shifts in both inputs and outputs can result in combinatorial effects!
 
 \item Compositionality is one potential solution
 
\end{itemize}
% \vspace{1em}

\begin{center}
\incw{compositionality}{1}
\end{center}
 
\end{frame}


\begin{frame}{Limitation 3: Models are anti-causal}


\begin{itemize}
 \item Existing model don't follow the data-generation process
\begin{itemize}
   \item Discriminative modelling easier than generative
\end{itemize}

 \vo
 
  
 \vo 
 
 \item Causal modelling is the \textbf{right solution} to deal with distribution shifts
 
 \vo
 
%  \begin{itemize}
%  \item Both for inputs and intermediary variables
% \end{itemize}
\end{itemize}


\begin{center}
\incw{causality}{1}
\end{center}
 
\end{frame}


\begin{frame}{Method: We perform image reconstruction by combining two models\\
% \begin{itemize}
\ \ \ \ \ \  1. a pre-trained generator G (StyleGAN2)\\
\ \ \ \ \ \  2. a known forward corruption model $f_1$
% \end{itemize}
}



\begin{columns}[t]
 \begin{column}{0.6\textwidth}
\centering
 
\begin{overprint}
 \onslide<1> \incw{brgm_diagram_loss}{1}
 \onslide<2-> \incw{brgm_diagram_all}{1}
\end{overprint} 
 \onslide<3> Ours
 \end{column}

 \begin{column}{0.3\textwidth}
  \centering

 \onslide<3> \incw{task-specific}{1}
 \onslide<3> Previous

 
 \end{column}
\end{columns} 
 


 
\end{frame}

\newcommand{\ci}[1]{\circ{#1}}
\newcommand{\wplus}{$\mathcal{W}^{+}$ }
\newcommand{\loss}{\mathcal{L}}

\begin{frame}{Reconstructed image is given by computing the Bayesian maximum a-posteriori (MAP) estimate\\
}



\begin{itemize}
 \item We optimise:
$$ w^* = \argmax_w p(w)p(I|w)$$

\item For uninformative prior $p(w)$ and Gaussian noise model (pixelwise independent), we get:

$$ w^* = \argmin_w || I - f \circ G (w) ||_2^2$$

\item This can be optimised with SGD

\item Once we get $w^*$, the the reconstructed image is $G(w^*)$

\end{itemize}

\begin{center}
\vt
\incw{brgm_diagram_loss}{0.6}
\end{center}
 
\end{frame}

\begin{frame}{Reconstruction in this basic formulation doesn't work}

\begin{itemize}
 \item We started from the original StyleGAN2 inversion
 
 \vo
 
 \item Yet the reconstruction was not good
 
 \vo
 
 \item We reached suitable solutions only after several changes 
%  \item Finall posterior likelihood function was:
 
% \begin{equation}
% \begin{aligned}
% \label{bfinal}
% & w^* = \argmin_w \underbrace{\sum_i \left(\frac{w_i-\mu}{\sigma_i}\right)^2}_\text{prior on $w$} - 2\kappa \underbrace{\sum_{i,j} \frac{w_iw_j^T}{|w_i| |w_j|}}_\text{colinearity} \\
% & + \sigma_{pixel}^{-2} \underbrace{\norm{I - f \ci G(w)}_2^2}_\text{pixelwise loss} + \sigma_{percept}^{-2} \underbrace{\norm{I - \phi \ci f \ci G(w)}_2^2}_\text{perceptual loss} \\
% \end{aligned}
% \end{equation}
 
\end{itemize}

\begin{center}
\vt
\incw{evol}{1}
\end{center}
 
\end{frame}

\begin{frame}{Results on super-resolution using the FFHQ dataset}

\begin{itemize}
 \item We achieve state-of-the-art (SOTA) results on small inputs resolutions 16x16
 \item On larger resolutions ($>$32x32), we achieve very good results, albeit not SOTA
\end{itemize}

\begin{center}
\vt
\incw{sr}{1}
\end{center}
 
\end{frame}

\begin{frame}{Similar results on super-resolution for medical datasets}

\begin{itemize}
 \item We achieve state-of-the-art (SOTA) results on small inputs resolutions 16x16
 \item On larger resolutions ($>$32x32), we achieve very good results, albeit not SOTA
\end{itemize}

\begin{center}
\vt
\incw{srmed}{0.7}
\end{center}
 
\end{frame}

\begin{frame}{Inpainting also achieves state-of-the-art results}

\begin{itemize}
 \item Best previous method (SN-PatchGAN, CVPR 2019) does not work for large masks
 \item Our method can ``hypothesize'' missing structure
\end{itemize}

\begin{center}
% \vt
\incw{inpaint2}{0.61}
\end{center}
 
\end{frame}

\begin{frame}{Inpainting also achieves state-of-the-art results}

\begin{itemize}
 \item Best previous method (SN-PatchGAN, CVPR 2019) does not work for large masks
 \item Our method can ``hypothesize'' missing structure
\end{itemize}

\begin{center}
\vt
\incw{inpaint_xray}{0.5}\incw{inpaint_brains}{0.5}
\end{center}
 
\end{frame}


\begin{frame}{Results confirmed through quantitative evaluation}

\begin{columns}[t]
 \begin{column}{0.5\textwidth}
\begin{itemize}
 \item Three different datasets, at different resolutions
 
 \vt
 
 \item Human study with 20 raters
 
%  \vt
 
\end{itemize}
  
 \end{column}
 \begin{column}{0.5\textwidth}
 \centering

Super-resolution
\incw{sr_eval}{0.9}

\vo

Inpainting
\incw{inpaint_eval}{0.9}

\vo

Human evaluation
\incw{human_eval}{0.9}

\end{column}

 
\end{columns}




 
\end{frame}

\begin{frame}{Our method also has limitations}

\begin{itemize}
 \item It can fail for images that are too dissimilar to the training ones
 \begin{itemize}
 \item Because generator cannot extrapolate easily
 \end{itemize}
 \begin{center}
 \incw{failure}{0.6} 
 \end{center}
 
 \item Can be inconsistent with the input image
 \begin{center}
 \incw{inconsistency}{0.6}
 \end{center}
 
\end{itemize}
 
\end{frame}


\begin{frame}{Conclusion}
 
 \begin{itemize}
  \item Proposed a method for image reconstruction using pre-trained deep generative models
  
  \vt
  
  \item Solution is given by the Bayesian MAP estimate
  
  \vt
  
  \item State-of-the-art results on super-resolution and inpainting
  
 \end{itemize}

 
\end{frame}




