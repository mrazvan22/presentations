\documentclass[8pt,xcolor=table,aspectratio=169]{beamer}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{transparent}
\usepackage{epstopdf} %converting to PDF
\usepackage{multicol} 
\usepackage{animate}[2017/05/18]

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
% \usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}
% \usepackage[thinc]{esdiff}

% \usepackage{pdfx}
 
% \usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}
\usepackage[table]{xcolor}    % loads also »colortbl« 
%  \usepackage{enumitem}
% \usepackage{ucltemplate}
\usepackage{color}

\usepackage{comment}

\usepackage{tabularx} % make width of table columns evenly distributed (see http://tex.stackexchange.com/questions/60601/evenly-distributing-column-widths)
% \newcolumntype{Y}{>{\centering\arraybackslash}X}

% make entire row bold or italic in table
\newcommand\setrow[1]{\gdef\rowmac{#1}#1\ignorespaces}
\newcommand\clearrow{\global\let\rowmac\relax}
\clearrow


\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%


%\usepackage{pgfgantt} % for grantt charts
\usepackage{rotating}
\usepackage[graphicx]{realboxes}
\usepackage[export]{adjustbox}
\usepackage{array}

\usepackage{rotating}
% \usepackage{tabularx, booktabs} % make width of table columns evenly distributed (see http://tex.stackexchange.com/questions/60601/evenly-distributing-column-widths)
% \newcolumntype{Y}{>{\centering\arraybackslash}X}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{tikz}
\usetikzlibrary{bayesnet}
\usetikzlibrary{decorations}
\usetikzlibrary{arrows,positioning, shapes.symbols,shapes.callouts,patterns,shapes,chains,calc,backgrounds,fadings}

% \definecolor{parCol}{rgb}{0.1, 0.1, 1}
% \definecolor{stCol}{rgb}{0.1, 0.6, 0.1}
% \definecolor{bothCol}{rgb}{0, 0.5, 0.5}

\definecolor{parCol}{rgb}{0, 0, 0}
\definecolor{stCol}{rgb}{0, 0, 0}
\definecolor{bothCol}{rgb}{0, 0, 0}
\definecolor{blue3}{HTML}{86B7FC} % med blue
\definecolor{blue1}{HTML}{B5F1FF} % light blue
\definecolor{blue2}{HTML}{E0F9FF} % very light blue

\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\setlength{\tabcolsep}{0.2em}

 
 %% OVERVIEW OF WORK SO FAR %%
 
%Information to be included in the title page:
\title{Medical Image Generation and Analysis using Bayesian Generative Models}
\author[Raz]{
R\u{a}zvan V. Marinescu\vspace{1em}}

\institute{\small{Massachusetts Institute of Technology}

% \vspace{0em}
% \small{Centre for Medical Image Computing, University College London, UK}
}

\date{}

% logo of my university
\titlegraphic{
   \begin{figure}
%    \begin{subfigure}{0.32\textwidth}
%    \hspace{2em}
%    \includegraphics[height=1.0cm]{ucl_logo}
%    \end{subfigure}
   \begin{subfigure}{0.32\textwidth}
   \centering
   \includegraphics[height=1.0cm]{MIT_logo.png} 
   \end{subfigure}
%    \begin{subfigure}{0.32\textwidth}
%    \centering
%    \includegraphics[height=1.0cm]{pondLogo.png} 
%    \end{subfigure}
   \end{figure}
   
%    \tiny{Slides available online: https://people.csail.mit.edu/razvan/talk/martinos2019/pres.pdf}
}

\setbeamercolor{frametitle}{fg=black}
\setbeamercolor{author in head/foot}{fg=black, bg=white} 
\setbeamercolor{institute in head/foot}{fg=black, bg=white} 
\setbeamercolor{title in head/foot}{fg=black, bg=white}
\setbeamercolor{date in head/foot}{fg=black, bg=white}

\setbeamersize{text margin left=10pt,text margin right=10pt}
% \setbeamertemplate{frametitle}{
%     \vspace{0.9em}
%     \insertframetitle
% %     \vspace{-3em}
% }
\setbeamertemplate{frametitle}{%
    \vspace{0.5em}
    \usebeamerfont{frametitle}\insertframetitle%
    \vphantom{g}% To avoid fluctuations per frame
    %\hrule% Uncomment to see desired effect, without a full-width hrule
    \par% <-- added
    \hspace*{-\dimexpr0.5\paperwidth-0.5\textwidth}% <-- calculation of left margin width
    \rule[0.5\baselineskip]{\paperwidth}{0.4pt}%
}

\setbeamertemplate{footline}
{
  \vspace{-3em}
  \leavevmode%
   \rule{\paperwidth}{0.3pt}
  \hbox{%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
    \usebeamerfont{author in head/foot}Razvan V. Marinescu
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{institute in head/foot}%
    \usebeamerfont{institute in head/foot}razvan@csail.mit.edu
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{institute in head/foot}%
    \usebeamerfont{institute in head/foot}http://razvan.csail.mit.edu
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.2\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
    \usebeamerfont{title in head/foot}\insertsection
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.10\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
    \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
    \insertframenumber{} / \inserttotalframenumber\hspace*{2ex}
  \end{beamercolorbox}}%
  \vskip0pt%
}

% \usepackage{beamerthemesplit}

\newcommand{\backupbegin}{
   \newcounter{finalframe}
   \setcounter{finalframe}{\value{framenumber}}
}
\newcommand{\backupend}{
   \setcounter{framenumber}{\value{finalframe}}
}


\makeatletter
\long\def\beamer@author[#1]#2{%
  \def\and{\tabularnewline}
  \def\insertauthor{\def\inst{\beamer@insttitle}\def\and{\tabularnewline}%
  \begin{tabular}{rl}#2\end{tabular}}%
  \def\beamer@shortauthor{#1}%
  \ifbeamer@autopdfinfo%
    \def\beamer@andstripped{}%
    \beamer@stripands#1 \and\relax
    {\let\inst=\@gobble\let\thanks=\@gobble\def\and{, }\hypersetup{pdfauthor={\beamer@andstripped}}}
  \fi%
}
\makeatother
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{caption}[numbered]
\setbeamercolor{caption name}{fg=black}
\setbeamercolor{itemize item}{fg=black}
\setbeamercolor{itemize subitem}{fg=black}
\setbeamercolor{enumerate item}{fg=black}
\setbeamercolor{enumerate subitem}{fg=black}
\setbeamertemplate{enumerate item}[default]
\setbeamertemplate{enumerate subitem}[default]

\makeatletter
\let\@@magyar@captionfix\relax
\makeatother
\begin{document}
 
\section{Introduction}

\frame{\titlepage}
 
\setbeamerfont{frametitle}{size=\large}

\newcommand{\upgradeReportLoc}{../../upgrade_report}
\newcommand{\epsrcPresLoc}{\upgradeReportLoc/epsrcPres}
\newcommand{\jointModellingDiseaseLoc}{../../jointModellingDisease}
\newcommand{\pcaLongPaperLoc}{../../PCA_long_paper}
\newcommand{\voxFld}{../../voxelwiseDPM}
\newcommand{\tadpoleFld}{../../tadpole}
\newcommand{\diffEqModelFld}{../../diffEqModel}

\newcommand{\outFolder}{../overview/modelDiagram}
\newcommand{\lw}{0.5mm}

\newcommand{\yes}{{\LARGE \textcolor{green!50!black}{\checkmark} \par}}
\newcommand{\no}{{\LARGE \textcolor{red}{\xmark} \par}}



\newcommand*{\pcaLongFigs}{\pcaLongPaperLoc/figures}


% \includeonlyframes{1-20}
%\includeonlyframes{current}



\newcommand{\ovHeight}{2cm}
\newcommand{\vo}{\vspace{1em}}
\newcommand{\vt}{\vspace{2em}}
\newcommand{\vth}{\vspace{3em}}


% % TODO continue with overview, move into commands
\newcommand{\ovEBM}{
\begin{subfigure}{0.47\textwidth}
\centering
1. Modelled progression of PCA and tAD\\
(using existing methods)
\includegraphics[height=\ovHeight]{ebm_thumb.png}
\end{subfigure}
}

\newcommand{\ovVWDPM}{
\begin{subfigure}{0.47\textwidth}
\centering
% \vspace{2.8em}
2. Developed Novel Spatio-temporal Model \\ (DIVE)\\
\includegraphics[height=\ovHeight]{\upgradeReportLoc/images/vwdpm/blend14_adniThavgFWHM0InithistCl3Pr0Ra1_VWDPMStd.png}
\end{subfigure}
}


\newcommand{\ovDKT}{
\begin{subfigure}{0.47\textwidth}
\centering
\vspace{2em}
3. Developed Novel Transfer Learning \\ method (DKT) \\
\vspace{0.5em}
\includegraphics[height=2.2cm]{\jointModellingDiseaseLoc/paper/figures/disease_knowledge_transfer.pdf}
\end{subfigure}
}


\newcommand{\ovTadpole}{
\begin{subfigure}{0.47\textwidth}
\centering
\vspace{-2em}
4. Organised TADPOLE Competition\\
\vspace{1em}
\includegraphics[height=1.2cm,valign=t]{\upgradeReportLoc/epsrcPres/tadpole} 
\end{subfigure}
}

\newcommand{\ovPainter}{
\begin{subfigure}{\textwidth}
\centering
\vspace{0.5em}
5. Created BrainPainter software\\
\includegraphics[height=1.5cm]{cortical-front_1}\includegraphics[height=1.5cm]{cortical-back_1}\includegraphics[height=1.5cm]{subcortical_1}
\end{subfigure}
}


\definecolor{light-gray}{gray}{0.6}


\newcommand{\inc}[1]{\includegraphics[width=\columnwidth, trim=4 4 4 4, clip]{#1}}
\newcommand{\incw}[2]{\includegraphics[width=#2\columnwidth, trim=4 4 4 4, clip]{#1}}

\begin{frame}{Machine Learning algorithms have achieved impressive milestones}

\begin{columns}[t]
\begin{column}{0.5\textwidth}
\centering
\begin{figure}
\vspace{-2em}

 Object detection (YOLO)
 \incw{yolo}{0.8}
 
 \vt
 
  Image Generation (StyleGAN2)
 \incw{stylegan_small}{0.8}
\end{figure}

\end{column}
\begin{column}{0.5\textwidth}
\centering
Text-to-Image Generation (DALL-E)
\inc{dalle2}
prompt: ``an armchair in the shape of an avocado''

\vspace{1.5em}

Text generation (GPT-3)
\inc{gpt3}
\end{column}

\end{columns}

\vo 

\begin{itemize}
 \item Largely driven by increases in data and compute
\end{itemize}

 
 
\end{frame}


\begin{frame}{However, such milestones have not been translated to medical applications}

\begin{columns}[t]
\begin{column}{0.5\textwidth}
\centering

\begin{itemize}
\item Prediction of clinical variables not always working: 
\begin{itemize}
\item No algorithm/33, could predict cognitive scores in Alzheimer's\\ (TADPOLE Challenge, Marinescu 2020)
\end{itemize}
\vspace{4em}

\item Generated images are crude, not high-resolution, mostly 2D

\vspace{4em}

% \item Segmentation of pathologies and organs still inaccurate:
% \begin{itemize}
% \item SOTA placenta segmentation is \textcolor{red}{semi}-automatic
% \end{itemize}


\end{itemize}


\end{column}
\begin{column}{0.5\textwidth}
\centering
Brain MRI generation (Han, 2018)
\begin{figure}
\inc{brain-gen}

\vo

%Pneumonia segmentation (Wang, 2020)
%\incw{medseg}{0.7}

% Placenta segmentation (Wang, 2020)
% \incw{semi-automatic}{0.7}


\end{figure}
\end{column}
\end{columns}

 
 
\end{frame}


% Of 179 persons (average age, 86.9 years) with probable AD, 87.7% had pathologically confirmed AD, and 45.8% had mixed pathologies, most commonly AD with macroscopic infarcts (n = 54), followed by AD with neocortical LB disease (n = 19) and both (n = 8). 
% Of the 134 persons with MCI, 54.4% had pathologically diagnosed AD (58.7% amnestic; 49.2% nonamnestic); 19.4% had mixed pathologies (22.7% amnestic; 15.3% nonamnestic). Macroscopic infarcts without pathologically diagnosed AD accounted for 4.5% of probable AD, 13.3% of amnestic MCI, and 18.6% of nonamnestic MCI. Pure neocortical LB disease was uncommon in all persons with cognitive impairment (<6%). Microscopic infarcts (without macroscopic infarcts) were common as a mixed pathology, but rarely accounted for a clinical diagnosis of probable AD (n = 4) or MCI (n = 3).

\begin{frame}{Why are Machine Learning models not working on medical applications?}

\vspace{-2em}


\begin{columns}[t]
\begin{column}{0.5\textwidth}
\centering

\textbf{\large Lack of good labels}
% \begin{itemize}
% \item Lack of ground truth 

% ``Probable'' Alzheimer's disease diagnosis
\begin{itemize}
%  \item 

\item Alzheimer's diagnosis accuracy just 42\%

\begin{center}
\incw{ad_chart_schneider}{0.4}\\ 
\end{center}

\vspace{2.7em}

\item Labels are categorical instead of continuous\\
\vo
\incw{brain_prog_thresh}{1}

\end{itemize}

 \vspace{2em}
 

% \item Alzheimer's clinical diagnois: Sensitivity 70\%--87\%; specificity 44\%--70\%  
% \vo 

%  \incw{goldstandard}{0.9}


% \end{itemize}


\end{column}
\begin{column}{0.5\textwidth}
\centering

\textbf{\large Lack of good input data/signal}
\begin{itemize}
\item Limited contrast

% \begin{itemize}
% \item Stroke scans with limited contrast
% \end{itemize}
\begin{center}
\incw{strokescan}{0.7}
\end{center}


\vspace{2em}

\item Low-resolution

\begin{center}
\incw{stroke_lowres2}{0.4} 
\end{center}



% \item Small datasets, inability to scale 
% 
% \begin{itemize}
% \item most have  $<100$ scans (Maier-Hein, 2018)
% \end{itemize}
% \incw{imgcount}{0.7}


\end{itemize}


\end{column}
\end{columns}

 
 
\end{frame}

\newcommand{\diagfld}{brgm_diagram}
\newcommand{\fstikz}[1]{\footnotesize{#1}}


\newcommand{\brgmprev}{
\begin{tikzpicture}[scale=0.5, every node/.style={scale=0.5}]

\def\rightimgX{4.5}

%top image center
\node (cxr_img) at (1, 3.5) {\includegraphics[width=2cm]{\diagfld/brain_target}};
\node (cxr_text) at (1,4.75) {\footnotesize{Low Res.}};

%top image left
\node (blur_img) at (\rightimgX, 3.5) {\includegraphics[width=2cm]{\diagfld/brin_clean}};
\node (blur_text) at (\rightimgX,4.75) {\footnotesize{High Res.}};

%top image center
\node (cxr_img) at (1, 1) {\includegraphics[width=2cm]{\diagfld/crop.png}};
%top image left
\node (blur_img) at (\rightimgX, 1) {\includegraphics[width=2cm]{\diagfld/original.png}};

\node (left_img_top_out) at (2,3.5) {};
\node (right_img_top_in) at (\rightimgX - 1, 3.5) {};

\draw[->, thick]
(left_img_top_out)
to
(right_img_top_in) ;


\node (left_img_top_out_2) at (2,1) {};
\node (right_img_top_in_2) at (\rightimgX - 1, 1) {};

\draw[->, thick]
(left_img_top_out_2)
to
(right_img_top_in_2) ;


\node (left_img_top_in) at (2,2.5) {};
\node (right_img_top_out) at (\rightimgX - 1, 2.5) {};

\node (rng_text) at (2.75,3.75) {$f_1^{-1}(I)$};
\node (rng_text) at (2.75,3.25) {\fstikz{Learned}};
\node (rng_text) at (2.75,3) {\fstikz{Inverse}};
\node (rng_text) at (2.75,2.75) {\fstikz{Corruption}};

\node (rng_text) at (2.75,1.25) {$f_2^{-1}(I)$};

\end{tikzpicture}
}

\newcommand{\brgmours}{
\begin{tikzpicture}[scale=0.75, every node/.style={scale=0.75}]

\def\rightimgX{4.5}

%Top left
\filldraw[fill=gray!50!white, draw=black, label={Latent}] (-2,2.5) rectangle (-1.5,4.5);
\node (rng_text) at (-1.75,4.75) {\footnotesize{Latent}};
\node (rng_text) at (-1.75,3.5) {$w$};

%top image center
\node (cxr_img) at (1, 3.5) {\includegraphics[width=2cm]{\diagfld/brain_clean}};
\node (cxr_text) at (1,4.75) {\footnotesize{High Res.}};

%top image right
\node (blur_img) at (\rightimgX, 3.5) {\includegraphics[width=2cm]{\diagfld/brain_target}};
\node (blur_text) at (\rightimgX,4.75) {\footnotesize{Low Res.}};

\node (blur_img) at (\rightimgX+2.3, 3.5) {\includegraphics[width=2cm]{\diagfld/brain_target}};
\node (blur_text) at (\rightimgX+2.3,4.75) {\footnotesize{Input}};

\draw[decoration={brace,mirror,raise=5pt},decorate]
  (4.5,2.5) -- node[below=6pt] {loss} (6.8,2.5);


\node (rng_top_out) at (-1.5,3.5) {};
\node (center_img_left_in) at (0, 3.5) {};

\draw[->, thick]
(rng_top_out)
to
(center_img_left_in) ;
@inproceedings{roth2005fields,
  title={Fields of experts: A framework for learning image priors},
  author={Roth, Stefan and Black, Michael J},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={2},
  pages={860--867},
  year={2005},
  organization={IEEE}
}
\node (left_img_top_out) at (2,3.5) {};
\node (right_img_top_in) at (\rightimgX - 1, 3.5) {};

\draw[->, thick]
(left_img_top_out)
to
(right_img_top_in) ;

\node (left_img_top_in) at (2,2.5) {};
\node (right_img_top_out) at (\rightimgX - 1, 2.5) {};

% \draw[->, dashed, blue, thick]
% (right_img_top_out)
% to [in=-60, out=-120]
% (left_img_top_in) ;


\node (left_img_bot_out) at (0,2.5) {};
\node (rng_bot_out) at (-1.5, 2.5) {};
\draw[->, dashed, red, thick]
(rng_bot_out)
to [in=-120, out=-60]
(left_img_bot_out);

\node (rng_text) at (-0.75,3.75) {$G(w)$};
\node (rng_text) at (-0.75,3.25) {\fstikz{Image}};
\node (rng_text) at (-0.75,3) {\fstikz{Generation}};

\node (rng_text) at (2.75,3.75) {$f_1$};
\node (rng_text) at (2.75,3.25) {\fstikz{Known}};
\node (rng_text) at (2.75,3) {\fstikz{Corruption}};

\node (rng_text) at (-0.75,1.75) {\fstikz{Learned a-priori}};
\node (rng_text) at (-0.75,1.5) {\fstikz{given High Res Data}};
% \node (rng_text) at (-0.75,1.25) {\fstikz{given High Res Data}};

\node (rng_text) at (-0.5,0.75) {\fstikz{Can be redone}};
\node (rng_text) at (-0.5,0.5) {\fstikz{using the same $G(w)$}};
\node (rng_text) at (-0.5,0.25) {\fstikz{for multiple $f_i$}};


% \node (rng_text) at (2.75,1.75) {\fstikz{Optimized at}};
% \node (rng_text) at (2.75,1.5) {\fstikz{Test Time}};



\node (left_img_center_out) at (1,2.5) {};
\node (right_bot_out_extra) at (3.9 - 1, 1) {};
\draw[->, thick]
(left_img_center_out)
to [in=90, out=-90]
(1,1) 
to [out=0, in=180]
(right_bot_out_extra);

\node (right_bot_out_extra_2) at (3.9 - 1, 0.5) {};
\draw[->, thick]
(left_img_center_out)
to [in=90, out=-90]
(1,0.5) 
to [out=0, in=180]
(right_bot_out_extra_2);


\node (rng_text) at (1.75,1.25) {$f_2$};
\node (rng_text) at (1.75,0.75) {$f_3$};
\node (rng_text) at (1.75,0.25) {$\vdots$};


\node (blur_img) at (3.5+0.5, 0.5) {\includegraphics[width=1cm]{\diagfld/brain_kspace.png}};
\node (blur_img) at (3.5, 1.0) {\includegraphics[width=1cm,frame]{\diagfld/brain_inpaint}};

\end{tikzpicture}
}


\newcommand{\brgmoursshort}{
\begin{tikzpicture}[scale=0.75, every node/.style={scale=0.75}]

\def\rightimgX{4.5}

%Top left
\filldraw[fill=gray!50!white, draw=black, label={Latent}] (-2,2.5) rectangle (-1.5,4.5);
\node (rng_text) at (-1.75,4.75) {\footnotesize{Latent}};
\node (rng_text) at (-1.75,3.5) {$w$};

%top image center
\node (cxr_img) at (1, 3.5) {\includegraphics[width=2cm]{\diagfld/brain_clean}};
\node (cxr_text) at (1,4.75) {\footnotesize{High Res.}};

%top image right
\node (blur_img) at (\rightimgX, 3.5) {\includegraphics[width=2cm]{\diagfld/brain_target}};
\node (blur_text) at (\rightimgX,4.75) {\footnotesize{Low Res.}};


% \draw[decoration={brace,mirror,raise=5pt},decorate]
%   (4.5,2.5) -- node[below=6pt] {loss} (6.8,2.5);


\node (rng_top_out) at (-1.5,3.5) {};
\node (center_img_left_in) at (0, 3.5) {};

\draw[->, thick]
(rng_top_out)
to
(center_img_left_in) ;
@inproceedings{roth2005fields,
  title={Fields of experts: A framework for learning image priors},
  author={Roth, Stefan and Black, Michael J},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={2},
  pages={860--867},
  year={2005},
  organization={IEEE}
}
\node (left_img_top_out) at (2,3.5) {};
\node (right_img_top_in) at (\rightimgX - 1, 3.5) {};

\draw[->, thick]
(left_img_top_out)
to
(right_img_top_in) ;

\node (left_img_top_in) at (2,2.5) {};
\node (right_img_top_out) at (\rightimgX - 1, 2.5) {};

% \draw[->, dashed, blue, thick]
% (right_img_top_out)
% to [in=-60, out=-120]
% (left_img_top_in) ;


\node (left_img_bot_out) at (0,2.5) {};
\node (rng_bot_out) at (-1.5, 2.5) {};
% \draw[->, dashed, red, thick]
% (rng_bot_out)
% to [in=-120, out=-60]
% (left_img_bot_out);

% \node (rng_text) at (-0.75,3.75) {$G(w)$};
\node (rng_text) at (-0.75,3.25) {\fstikz{Image}};
\node (rng_text) at (-0.75,3) {\fstikz{Generation}};

% \node (rng_text) at (2.75,3.75) {$f_1$};
\node (rng_text) at (2.75,3.25) {\fstikz{Known}};
\node (rng_text) at (2.75,3) {\fstikz{Corruption}};

% \node (rng_text) at (-0.75,1.75) {\fstikz{Learned a-priori}};
% \node (rng_text) at (-0.75,1.5) {\fstikz{given High Res Data}};
% % \node (rng_text) at (-0.75,1.25) {\fstikz{given High Res Data}};
% 
% \node (rng_text) at (-0.5,0.75) {\fstikz{Can be redone}};
% \node (rng_text) at (-0.5,0.5) {\fstikz{using the same $G(w)$}};
% \node (rng_text) at (-0.5,0.25) {\fstikz{for multiple $f_i$}};


% \node (rng_text) at (2.75,1.75) {\fstikz{Optimized at}};
% \node (rng_text) at (2.75,1.5) {\fstikz{Test Time}};



% \node (left_img_center_out) at (1,2.5) {};
% \node (right_bot_out_extra) at (3.9 - 1, 1) {};
% \draw[->, thick]
% (left_img_center_out)
% to [in=90, out=-90]
% (1,1) 
% to [out=0, in=180]
% (right_bot_out_extra);
% 
% \node (right_bot_out_extra_2) at (3.9 - 1, 0.5) {};
% \draw[->, thick]
% (left_img_center_out)
% to [in=90, out=-90]
% (1,0.5) 
% to [out=0, in=180]
% (right_bot_out_extra_2);


% \node (rng_text) at (1.75,1.25) {$f_2$};
% \node (rng_text) at (1.75,0.75) {$f_3$};
% \node (rng_text) at (1.75,0.25) {$\vdots$};


% \node (blur_img) at (3.5+0.5, 0.5) {\includegraphics[width=1cm]{\diagfld/brain_kspace.png}};
% \node (blur_img) at (3.5, 1.0) {\includegraphics[width=1cm,frame]{\diagfld/brain_inpaint}};

\end{tikzpicture}
}


\begin{frame}{What can we do?}


\vspace{-8em}
\begin{columns}[t]
\begin{column}{0.5\textwidth}
\centering

\textbf{\large Lack of good labels}

% \begin{itemize}
% \item Alzheimer's diagnosis accuracy just 42\%
% % \begin{itemize}
% %  \item Infer continuous disease staging
% %  
% % %  \incw{severity}{0.7}
% % \end{itemize}
% 
%  \vspace{2em}
%  
%  \item Noisy labels
% % \begin{itemize}
% %    \item Infer true labels from noisy ones  
% % \end{itemize}
% 
% % \incw{goldstandard}{0.7}
% \end{itemize}

\vspace{2em}

% \vspace{-4em}

\end{column}
\begin{column}{0.5\textwidth}
\centering

\textbf{\large Lack of good input data/signal}

% \vspace{-1.5em}

% \begin{itemize}
% \item Lack of good input data
% 
% % \begin{itemize}
% %   \item Reconstruct better images
% % \end{itemize}
% % \incw{strokescan}{0.7}
% 
% \vspace{0.5em}
% 
% \item Small datasets, inability to scale 
% % \begin{itemize}
% % \item Acquire more data
% % \item Design algorithms for small datasets
% % % \begin{itemize}
% % %  \item Transfer learning
% % %  \item Few-shot or Zero-shot learning
% % % \end{itemize}
% % 
% % \end{itemize}
% % \incw{imgcount}{0.7}
% \end{itemize}

\vspace{2em}




\end{column}
\end{columns}


\begin{columns}[t]
\begin{column}{0.5\textwidth}
\centering

Solution: Unsupervised Learning of Continuous Dynamics\\
= Disease Progression Modelling\\
\vo

%Time-series model with\\ latent disease stage\\
% = Disease Progression Model\\
%\includegraphics[height=\ovHeight]{\upgradeReportLoc/images/vwdpm/blend14_adniThavgFWHM0InithistCl3Pr0Ra1_VWDPMStd.png}
\includegraphics[height=3cm]{dpm_small}

\end{column}
\begin{column}{0.5\textwidth}
\centering

Solution: Image Reconstruction\\ using Deep Generative Models\\
\vo
% \includegraphics[height=2cm, trim=6 6 6 6,clip]{brgm_diagram_small}
\brgmoursshort

\end{column}
\end{columns}

\end{frame}


\begin{frame}{Outline}

\begin{enumerate}
 \item Disease progression modelling of Alzheimer's disease 
 \begin{enumerate} 
  \item Towards unsupervised clustering of biomarker trajectories\\
 \end{enumerate}
   
% \includegraphics[height=2cm]{dpm_small} 
% \vt 
%  \item Unsupervised clustering of trajectories
 
   \begin{tikzpicture}[scale=1]
     \node (roi) at (0,0) {\includegraphics[height=1.5cm]{dpm_small}};
     \node (vw) at (4,0) {\includegraphics[height=1.5cm]{\voxFld/selected_resfiles/adniPet/atrophyExtent24_adniPetInitk-meansCl18Pr1Ra1_VDPM_MRF.png}};
     \draw[line width=1.5,->] (roi) -> (vw);
  \end{tikzpicture}
  
  \vt

 \item Image Reconstruction using Deep Generative Models\\
%  \includegraphics[height=1.5cm, trim=6 6 300 6,clip]{brgm_diagram_small}
\brgmoursshort
\vt
 
  \item Future work\\

\end{enumerate}
 


\end{frame}


\begin{frame}{Outline}

\begin{enumerate}
 \item \textbf{Disease progression modelling of Alzheimer's disease}
 \begin{enumerate} 
  \item Towards unsupervised clustering of biomarker trajectories\\
 \end{enumerate}
   
% \includegraphics[height=2cm]{dpm_small} 
% \vt 
%  \item Unsupervised clustering of trajectories
 
   \begin{tikzpicture}[scale=1]
     \node (roi) at (0,0) {\includegraphics[height=1.5cm]{dpm_small}};
     \node (vw) at (4,0) {\includegraphics[height=1.5cm]{\voxFld/selected_resfiles/adniPet/atrophyExtent24_adniPetInitk-meansCl18Pr1Ra1_VDPM_MRF.png}};
     \draw[line width=1.5,->] (roi) -> (vw);
  \end{tikzpicture}
  
  \vt

 \item Image Reconstruction using Deep Generative Models\\
%  \includegraphics[height=1.5cm, trim=6 6 300 6,clip]{brgm_diagram_small}
\brgmoursshort
\vt
 
  \item Future work\\

\end{enumerate}
\end{frame}


\input{dive.tex}


\begin{frame}{Outline}

\begin{enumerate}
 \item Disease progression modelling of Alzheimer's disease
 \begin{enumerate} 
  \item Towards unsupervised clustering of biomarker trajectories\\
 \end{enumerate}
   
% \includegraphics[height=2cm]{dpm_small} 
% \vt 
%  \item Unsupervised clustering of trajectories
 
   \begin{tikzpicture}[scale=1]
     \node (roi) at (0,0) {\includegraphics[height=1.5cm]{dpm_small}};
     \node (vw) at (4,0) {\includegraphics[height=1.5cm]{\voxFld/selected_resfiles/adniPet/atrophyExtent24_adniPetInitk-meansCl18Pr1Ra1_VDPM_MRF.png}};
     \draw[line width=1.5,->] (roi) -> (vw);
  \end{tikzpicture}
  
  \vt

 \item \textbf{Image Reconstruction using Deep Generative Models}\\
%  \includegraphics[height=1.5cm, trim=6 6 300 6,clip]{brgm_diagram_small}
\brgmoursshort
\vt
 
  \item Future work\\

\end{enumerate}
\end{frame}


% \input{brgm.tex}


\begin{frame}{Outline}

\begin{enumerate}
 \item Disease progression modelling of Alzheimer's disease
 \begin{enumerate} 
  \item Towards unsupervised clustering of biomarker trajectories\\
 \end{enumerate}
   
% \includegraphics[height=2cm]{dpm_small} 
% \vt 
%  \item Unsupervised clustering of trajectories
 
   \begin{tikzpicture}[scale=1]
     \node (roi) at (0,0) {\includegraphics[height=1.5cm]{dpm_small}};
     \node (vw) at (4,0) {\includegraphics[height=1.5cm]{\voxFld/selected_resfiles/adniPet/atrophyExtent24_adniPetInitk-meansCl18Pr1Ra1_VDPM_MRF.png}};
     \draw[line width=1.5,->] (roi) -> (vw);
  \end{tikzpicture}
  
  \vt

 \item Image Reconstruction using Deep Generative Models\\
%  \includegraphics[height=1.5cm, trim=6 6 300 6,clip]{brgm_diagram_small}
\brgmoursshort
\vt
 
  \item \textbf{Future work}\\

\end{enumerate}
\end{frame}


\begin{frame}{Future work}


\vspace{-2em}
\begin{columns}[t]
\begin{column}{0.5\textwidth}
\centering

Biological simulators\\
\incw{heartsim}{0.5}

\vt
\vt

Multimodal modelling\\
images + text + structural data  
\incw{xray}{0.3}\incw{medreport}{0.267}

\end{column}
\begin{column}{0.5\textwidth}
\centering

Better and faster reconstruction of medical images\\
\incw{mri_recon}{0.8}

\vt
\vt

Disease Progression Modelling
\incw{daninet}{1}

% \vo

% Domain knowledge from large-scale parsing of medical articles\\
% \incw{lotsoftext}{0.4}

\end{column}
\end{columns}


\end{frame}


\begin{frame}{Future work: Brain tissue and anatomy simulator}


Simulator for brain anatomy from genetics:
\begin{itemize}
 \item Using deep generative models
 \item Accouting for distributions shifts
 \item Following causal principles
\end{itemize}

\vt

\incw{brainsimulator}{0.9}

\end{frame}

\begin{frame}{Long-term vision: AI to contribute to all aspects of heathcare}



\begin{columns}[t]
\begin{column}{0.5\textwidth}
\centering


Early diagnosis and prognosis
\incw{smartwatch}{0.7}

AI augumenting humans\\
\incw{vr}{0.7}




\end{column}
\begin{column}{0.5\textwidth}
\centering


Robotic Surgery
\incw{roboticsurgery}{0.8}

\vo

Drug development
\incw{drugdevelopment}{0.8}


\end{column}
\end{columns}




\end{frame}


\end{document}



